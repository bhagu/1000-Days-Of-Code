{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preparing Data for Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMApnI5/UaDlOUH8lZUD4lO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagu/1000-Days-Of-Code/blob/main/Preparing_Data_for_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_nMrQAZSXbs"
      },
      "source": [
        "#Preparing Data For Machine Learning - Pluralsight Course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jar5x3FISrEO"
      },
      "source": [
        "#Understanding the Need for Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsTv8-jeTFI2"
      },
      "source": [
        "##Module Focus\n",
        "Insufficient Data;\n",
        "Excessive or overly complex data;\n",
        "Non-representative data, missing data, outlier;\n",
        "Oversampling and understanding;\n",
        "Overfitting and underfitting models;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5HvZ6mej6FL"
      },
      "source": [
        "### Insufficient Data\n",
        "Leads to Overfitting/ Underfitting\n",
        "\n",
        "No great solution for insufficient data\n",
        "\n",
        "Simply need to find more data sources\n",
        "\n",
        "Dealing with Small Datasets\n",
        "\n",
        "Model complexity - Simpler model with fewer model parameters, Less susceptible to overfitting, e.g. Naive Bayes classifier, logistic regression, Use ensemble techniques\n",
        "\n",
        "Transfer learning - the practice of reusing a trained neural network that solves a problem similar to yours, usually leaving the network architeture unchanged and re-using some of all of the model weights\n",
        "\n",
        "Data augmentation - Increase the number of training samples, Perturbed images are a form of data augmentation, Scaling, rotation, affine transforms, Makes CNN training more robust\n",
        "\n",
        "Synthetic data - Artificially generate samples which mimic real world data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr9WNBdgltkE"
      },
      "source": [
        "###Too Much Data\n",
        "Data might be excessive in 2 ways\n",
        "\n",
        "- Curse of dimensionality: Too many columns/features\n",
        "- Outdated historical data: Too many rows\n",
        "\n",
        "Concept Drift: The relationship between features (X-variables) and labels (Y-variables) changes over time; ML models fail to keep up, and consequently their performance suffers\n",
        "\n",
        "Outdated historical data: If not eliminated, leads to concept drift;\n",
        "This is a serious issue in specific applications\n",
        "- Financial trading\n",
        "\n",
        "Usually require human expert to judge which rows to leave out\n",
        "\n",
        "Curse of dimensionality: 2 specific problems arise when too much data is available\n",
        "- Deciding which data is actually relevant\n",
        "- Aggregating very low-level data into useful features\n",
        "\n",
        "Easier problem to solve:\n",
        "- Feature selection: Deciding which data is actually relevant\n",
        "- Feautre engineering: Aggregating very low-level data into useful features\n",
        "- Dimensionality reduction: Reduce complexity without losing information\n",
        "\n",
        "Concept Hierarchy: A mapping that combines very low-level features (e.g. latitudes and longitudes) into more general, usable features (e.g. zip codes)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXjesEZoU-0"
      },
      "source": [
        "###Non-Representative Data\n",
        "Data is inaccurate, small errors have significant impact\n",
        "\n",
        "Account for data cleaning and processing time\n",
        "\n",
        "Data is not representative of the real world i.e. biased\n",
        "\n",
        "Leads to biased models that perform poorly in practice\n",
        "\n",
        "Mitigate using oversampling and undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riqKeIsXp5qJ"
      },
      "source": [
        "###Duplicate Data\n",
        "If data can be flagged as duplicate, problem relatively easy to solve\n",
        "- Simply de-duplicate\n",
        "\n",
        "Can be hard to identify in some applications\n",
        "- Real-time streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-TAlXO6ppqE"
      },
      "source": [
        "###Missing Data and Outliers\n",
        "Data cleaning procedures can help significantly mitigate the effects of\n",
        "- Missing data\n",
        "- Outliers\n",
        "\n",
        "Missing Data\n",
        "- Deletion\n",
        "- Imputation\n",
        "\n",
        "Deletion / Listwise Deletion: Delete an entire record (row) if a single value (column) is missing. Simple, but can lead to bias\n",
        "\n",
        "- Most common method in practices\n",
        "- Can reduce sample size significanlty\n",
        "- If values are not missing at random, can intriduce significant bias\n",
        "\n",
        "Imputation: Fill in missing values, rather than deleting records with missing values. Missing values are inferred from known data.\n",
        "\n",
        "- Methods range from very simple to very complex\n",
        "- Simplest method - Use column average\n",
        "- Can interpolate from nearby values \n",
        "- Can even build model to predict missing values\n",
        "\n",
        "Univariate Imputation: rely only on known values in same feature\n",
        "\n",
        "Multivariate imputation: Use all known data to infer missing value\n",
        "- Construct regression models from other columns to predict this column\n",
        "- Iteratively repeat for all columns\n",
        "\n",
        "Hot-deck Imputation:\n",
        "- Sort records based on any criteria\n",
        "- for each missing value, use immediately prior available value\n",
        "- \"Last Observation Carried Forward\"\n",
        "- For time-series data, equivalent to assuming no change since last measurement\n",
        "\n",
        "Mean Substitution:\n",
        "- For each missing value, substitute mean of all available values\n",
        "- Has effect of weakening correlations between columns\n",
        "- Can be problematic when bivariate analysis is required\n",
        "\n",
        "Regression:\n",
        "- Fit model to predict missing column based on other column values\n",
        "- Tends to strengthen correlations\n",
        "- Regression and mean substitution have complementary strengths\n",
        "\n",
        "Outliers\n",
        "- Identifying Outliers\n",
        "  - Distance from Mean\n",
        "  - Distance from fitted line\n",
        "- Coping with Outliers\n",
        "  - Drop\n",
        "  - Cap/Floor\n",
        "  - Set to mean\n",
        "\n",
        "Identifying Outliers\n",
        "\n",
        "More than 3 Standard deviation - Distance from mean\n",
        "\n",
        "Might also be data points that do not fit into the same relationship as the rest of the data\n",
        "\n",
        "\n",
        "Coping with Outliers\n",
        "- Always start by scrutinizing outliers\n",
        "- If erroneous observation\n",
        "  - Drop if all attributes of that point are erroneous\n",
        "  - Set to mean if only one attribute is erroneous\n",
        "- If genuine, legitimate outlier\n",
        "  - Leave as-is if model is not distorted\n",
        "  - Cap/Floor if model is distorted\n",
        "    - Need to first standardize data\n",
        "    - Cap positive outliers to +3\n",
        "    - Floor negative outliers to -3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsCbcILxu2dC"
      },
      "source": [
        "###Oversampling and Undersampling\n",
        "Techniques that intentionally add bias to the data in order to make it balanced\n",
        "\n",
        "Balacing Datasets\n",
        "- Oversampling uncommon x or y values\n",
        "- Undersampling of common x or y values\n",
        "\n",
        "Forcibly Balanced Datasets\n",
        "\n",
        "Oversampling and undersampling tend to\n",
        "- Reduce accuracy\n",
        "- Increase precision and recall\n",
        "\n",
        "Related techniques include\n",
        "- Case studies\n",
        "- Stratified sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd786kfuwhM7"
      },
      "source": [
        "###Overfitting and Underfitting\n",
        "Overfitting\n",
        "- Model has memorized the training data\n",
        "- Low training error\n",
        "- Doesn't work well in the real world\n",
        "- High test error\n",
        "\n",
        "Underfitting\n",
        "- Model unable to capture relationships in data\n",
        "- Performs poorly on the training data\n",
        "- Model too 'simple' to be useful"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0voCQR3b6xOj"
      },
      "source": [
        ""
      ]
    }
  ]
}